import streamlit as st
import asyncio
import time
import os
import tempfile
import zipfile
import io
from datetime import datetime
from typing import List, Dict
import subprocess
import sys
from pathlib import Path
import threading
import queue
import contextlib
from io import StringIO
import json
import uuid  # æ–°å¢å¯¼å…¥

# å¯¼å…¥ç°æœ‰æ¨¡å—
try:
    from workflow import run_workflow
    from utils import asave_result_to_file
    import marvin
    from pydantic_ai.models.openai import OpenAIModel
    from pydantic_ai.providers.openrouter import OpenRouterProvider
except ImportError as e:
    st.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    st.error("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…")

class StreamCapture:
    """æµå¼è¾“å‡ºæ•è·å™¨"""
    
    def __init__(self):
        self.output_queue = queue.Queue()
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        self.capturing = False
    
    def start_capture(self):
        """å¼€å§‹æ•è·è¾“å‡º"""
        self.capturing = True
        sys.stdout = self
        sys.stderr = self
    
    def stop_capture(self):
        """åœæ­¢æ•è·è¾“å‡º"""
        self.capturing = False
        sys.stdout = self.original_stdout
        sys.stderr = self.original_stderr
    
    def write(self, text):
        """å†™å…¥è¾“å‡º"""
        if self.capturing and text.strip():
            self.output_queue.put(text)
            # åŒæ—¶è¾“å‡ºåˆ°åŸå§‹stdout
            self.original_stdout.write(text)
        return len(text)
    
    def flush(self):
        """åˆ·æ–°ç¼“å†²åŒº"""
        self.original_stdout.flush()
    
    def get_output(self):
        """è·å–æ‰€æœ‰è¾“å‡º"""
        output = []
        while not self.output_queue.empty():
            try:
                output.append(self.output_queue.get_nowait())
            except queue.Empty:
                break
        return output

class WorkflowRunner:
    """å·¥ä½œæµæ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.results = []
        self.errors = []
        self.stream_capture = StreamCapture()
        self.log_counter = 0  # æ–°å¢è®¡æ•°å™¨
        self.setup_model()
    
    def setup_model(self):
        """è®¾ç½® AI æ¨¡å‹"""
        try:
            # è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„API key
            api_key = self.get_api_key()
            model = OpenAIModel(
                'anthropic/claude-sonnet-4',
                provider=OpenRouterProvider(api_key=api_key),
            )
            marvin.defaults.model = model
        except Exception as e:
            st.error(f"æ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
    
    def get_api_key(self):
        """ä»é…ç½®æ–‡ä»¶è¯»å–API key"""
        try:
            if os.path.exists("config.json"):
                with open("config.json", "r", encoding="utf-8") as f:
                    config = json.load(f)
                    api_key = config.get("api_key")
                    if not api_key:
                        raise ValueError("config.jsonä¸­æœªæ‰¾åˆ°api_key")
                    return api_key
            else:
                raise FileNotFoundError("config.jsonæ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            st.error(f"è¯»å–API keyå¤±è´¥: {e}")
            st.error("è¯·åœ¨config.jsonä¸­é…ç½®æœ‰æ•ˆçš„api_key")
            return None
    
    def save_api_key(self, api_key):
        """ä¿å­˜API keyåˆ°é…ç½®æ–‡ä»¶"""
        try:
            config = {"api_key": api_key}
            with open("config.json", "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            st.error(f"ä¿å­˜API keyå¤±è´¥: {e}")
            return False

    async def run_single_workflow(self, index: int = 0) -> Dict:
        """æ‰§è¡Œå•æ¬¡å·¥ä½œæµ"""
        try:
            print(f"ğŸš€ å¼€å§‹æ‰§è¡Œç¬¬ {index + 1} æ¬¡å·¥ä½œæµ...")
            result = await run_workflow()
            print(f"âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼Œå¼€å§‹ä¿å­˜ç»“æœ...")
            saved_file = await asave_result_to_file(result)
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {saved_file}")
            
            return {
                'success': True,
                'result': result,
                'saved_file': saved_file,
                'error': None
            }
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ ç¬¬ {index + 1} æ¬¡æ‰§è¡Œå¤±è´¥: {error_msg}")
            return {
                'success': False,
                'result': None,
                'saved_file': None,
                'error': error_msg
            }
    
    async def run_batch_workflows(self, count: int, progress_callback=None, log_callback=None):
        """æ‰¹é‡æ‰§è¡Œå·¥ä½œæµ"""
        self.results = []
        self.errors = []
        
        # å¼€å§‹æ•è·è¾“å‡º
        self.stream_capture.start_capture()
        
        try:
            for i in range(count):
                if progress_callback:
                    progress_callback(i, count)
                
                print(f"\n{'='*50}")
                print(f"ğŸ“Š æ‰§è¡Œè¿›åº¦: {i+1}/{count}")
                print(f"{'='*50}")
                
                result = await self.run_single_workflow(i)
                
                if result['success']:
                    self.results.append(result)
                    print(f"ğŸ‰ ç¬¬ {i+1} æ¬¡æ‰§è¡ŒæˆåŠŸå®Œæˆï¼")
                else:
                    self.errors.append({
                        'index': i + 1,
                        'error': result['error']
                    })
                    print(f"ğŸ’¥ ç¬¬ {i+1} æ¬¡æ‰§è¡Œå¤±è´¥ï¼")
                
                # è·å–å¹¶ä¼ é€’æ—¥å¿—
                if log_callback:
                    logs = self.stream_capture.get_output()
                    if logs:
                        log_callback(logs)
                
                # æ·»åŠ å°å»¶è¿Ÿé¿å…è¿‡å¿«è¯·æ±‚
                print(f"â³ ç­‰å¾… 0.5 ç§’åç»§ç»­...")
                await asyncio.sleep(0.5)
            
            if progress_callback:
                progress_callback(count, count)
                
        finally:
            # åœæ­¢æ•è·è¾“å‡º
            self.stream_capture.stop_capture()

def create_download_zip():
    """åˆ›å»ºåŒ…å«æ‰€æœ‰txtæ–‡ä»¶çš„ZIPåŒ…"""
    data_dir = Path("data")
    if not data_dir.exists():
        return None
    
    files = list(data_dir.glob("result_*.txt"))
    if not files:
        return None
    
    # åˆ›å»ºå†…å­˜ä¸­çš„ZIPæ–‡ä»¶
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for file in files:
            # æ·»åŠ æ–‡ä»¶åˆ°ZIPï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
            zip_file.write(file, file.name)
    
    zip_buffer.seek(0)
    return zip_buffer.getvalue()

def delete_all_txt_files():
    """åˆ é™¤æ‰€æœ‰ç”Ÿæˆçš„txtæ–‡ä»¶"""
    data_dir = Path("data")
    if not data_dir.exists():
        return 0
    
    files = list(data_dir.glob("result_*.txt"))
    deleted_count = 0
    
    for file in files:
        try:
            file.unlink()
            deleted_count += 1
        except Exception as e:
            st.error(f"åˆ é™¤æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
    
    return deleted_count

def show_api_config():
    """æ˜¾ç¤ºAPIé…ç½®é¢æ¿"""
    st.subheader("ğŸ”‘ API é…ç½®")
    
    runner = WorkflowRunner()
    
    # æ˜¾ç¤ºå½“å‰API keyï¼ˆéƒ¨åˆ†éšè—ï¼‰
    current_key = runner.get_api_key()
    masked_key = f"{current_key[:10]}...{current_key[-4:]}" if len(current_key) > 14 else "***"
    st.text(f"å½“å‰API Key: {masked_key}")
    
    # API keyä¿®æ”¹è¡¨å•
    with st.form("api_config_form"):
        new_api_key = st.text_input(
            "æ–°çš„ API Key",
            value=current_key,
            type="password",
            help="è¯·è¾“å…¥æœ‰æ•ˆçš„ OpenRouter API Key"
        )
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.form_submit_button("ğŸ’¾ ä¿å­˜", type="primary"):
                if not new_api_key.strip():
                    st.error("âŒ API Key ä¸èƒ½ä¸ºç©º")
                else:
                    if runner.save_api_key(new_api_key.strip()):
                        st.success("âœ… API Key ä¿å­˜æˆåŠŸï¼")
                        st.info("â„¹ï¸ æ–°é…ç½®å°†åœ¨ä¸‹æ¬¡æ‰§è¡Œå·¥ä½œæµæ—¶ç”Ÿæ•ˆ")
                        st.rerun()
        
        with col2:
            if st.form_submit_button("ğŸ” æµ‹è¯•"):
                test_api_key(new_api_key.strip())
        
        with col3:
            if st.form_submit_button("ğŸ”„ é‡ç½®"):
                default_key = "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"
                if runner.save_api_key(default_key):
                    st.success("âœ… å·²é‡ç½®ä¸ºé»˜è®¤ API Key")
                    st.rerun()

def test_api_key(api_key: str):
    """æµ‹è¯•API keyè¿æ¥"""
    if not api_key:
        st.error("âŒ è¯·å…ˆè¾“å…¥API Key")
        return
    
    with st.spinner("ğŸ” æµ‹è¯•APIè¿æ¥..."):
        try:
            test_model = OpenAIModel(
                'anthropic/claude-sonnet-4',
                provider=OpenRouterProvider(api_key=api_key),
            )
            
            import marvin
            old_model = marvin.defaults.model
            marvin.defaults.model = test_model
            
            # æ‰§è¡Œç®€å•æµ‹è¯•
            test_result = marvin.generate(
                str,
                instructions="è¯·å›å¤'è¿æ¥æˆåŠŸ'",
                n=1
            )
            
            # æ¢å¤åŸæ¨¡å‹
            marvin.defaults.model = old_model
            
            if test_result:
                st.success("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼")
            else:
                st.warning("âš ï¸ APIè¿æ¥æˆåŠŸï¼Œä½†è¿”å›ç»“æœä¸ºç©º")
                
        except Exception as e:
            st.error(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """ä¸»åº”ç”¨ç•Œé¢"""
    st.set_page_config(
        page_title="Glass3K Workflow æ‰§è¡Œå™¨",
        page_icon="ğŸ‘“",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # æ ‡é¢˜å’Œæè¿°
    st.title("ğŸ‘“ Glass3K Workflow æ‰§è¡Œå™¨")
    
    # æ·»åŠ é¡µé¢å¯¼èˆªæç¤º
    st.info("ğŸ’¡ **æ–°åŠŸèƒ½**: è®¿é—®ä¾§è¾¹æ ä¸­çš„ **ğŸ“… ä»»åŠ¡ç®¡ç†** é¡µé¢æ¥è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼")
    
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ æ‰§è¡Œé…ç½®")
        
        # æ‰§è¡Œæ¬¡æ•°é€‰æ‹©
        execution_count = st.number_input(
            "æ‰§è¡Œæ¬¡æ•°",
            min_value=1,
            max_value=100,
            value=5,
            help="é€‰æ‹©è¦æ‰§è¡Œ workflow.py çš„æ¬¡æ•°"
        )
        
        # é«˜çº§é€‰é¡¹
        with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
            show_detailed_logs = st.checkbox("æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—", value=True)
            show_realtime_output = st.checkbox("æ˜¾ç¤ºå®æ—¶è¾“å‡º", value=True)
            auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–°çŠ¶æ€", value=True)
        
        st.markdown("---")
        
        # APIé…ç½®åŒºåŸŸ
        show_api_config()
        
        st.markdown("---")
        
        # æ–‡ä»¶ç®¡ç†åŒºåŸŸ
        st.subheader("ğŸ“ æ–‡ä»¶ç®¡ç†")
        
        # åˆ·æ–°æŒ‰é’®
        col_refresh, col_spacer = st.columns([1, 2])
        with col_refresh:
            if st.button("ğŸ”„ åˆ·æ–°", use_container_width=True, help="åˆ·æ–°æ–‡ä»¶åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯"):
                st.rerun()
        
        # ç»Ÿè®¡ä¿¡æ¯
        data_dir = Path("data")
        file_count = 0
        total_size = 0
        
        if data_dir.exists():
            files = list(data_dir.glob("result_*.txt"))
            file_count = len(files)
            total_size = sum(f.stat().st_size for f in files)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ–‡ä»¶æ•°é‡", file_count)
        with col2:
            st.metric("æ€»å¤§å°", f"{total_size / 1024:.1f} KB")
        
        # æ–‡ä»¶æ“ä½œæŒ‰é’®
        if file_count > 0:
            zip_data = create_download_zip()
            if zip_data:
                st.download_button(
                    label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰æ–‡ä»¶",
                    data=zip_data,
                    file_name=f"glass3k_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                    mime="application/zip",
                    use_container_width=True
                )
            
            # åˆ é™¤æŒ‰é’®
            if st.button("ğŸ—‘ï¸ åˆ é™¤æ‰€æœ‰æ–‡ä»¶", use_container_width=True, type="secondary"):
                deleted_count = delete_all_txt_files()
                if deleted_count > 0:
                    st.success(f"âœ… å·²åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶")
                    st.rerun()
                else:
                    st.info("æ²¡æœ‰æ–‡ä»¶éœ€è¦åˆ é™¤")
        else:
            st.info("æš‚æ— æ–‡ä»¶å¯ç®¡ç†")
        
        st.markdown("---")
        
        # ç¯å¢ƒä¿¡æ¯
        st.subheader("ğŸ“‹ ç¯å¢ƒä¿¡æ¯")
        python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        st.text(f"Python: {python_version}")
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        workflow_exists = os.path.exists("workflow.py")
        config_exists = os.path.exists("config.json")
        st.text(f"workflow.py: {'âœ…' if workflow_exists else 'âŒ'}")
        st.text(f"config.json: {'âœ…' if config_exists else 'âš ï¸'}")
        
        # è™šæ‹Ÿç¯å¢ƒæ£€æŸ¥
        venv_active = os.environ.get('VIRTUAL_ENV') is not None
        st.text(f"è™šæ‹Ÿç¯å¢ƒ: {'âœ…' if venv_active else 'âš ï¸'}")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸš€ æ‰§è¡Œæ§åˆ¶")
        
        # æ‰§è¡ŒæŒ‰é’®
        if st.button(
            f"å¼€å§‹æ‰§è¡Œ ({execution_count} æ¬¡)",
            type="primary",
            use_container_width=True
        ):
            if not workflow_exists:
                st.error("âŒ workflow.py æ–‡ä»¶ä¸å­˜åœ¨ï¼")
                return
            
            # æ‰§è¡Œå·¥ä½œæµ
            run_workflows(execution_count, show_detailed_logs, show_realtime_output)
    
    with col2:
        st.subheader("ğŸ“Š å¿«é€Ÿç»Ÿè®¡")
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        data_dir = Path("data")
        if data_dir.exists():
            files = list(data_dir.glob("result_*.txt"))
            st.metric("å·²ç”Ÿæˆæ–‡ä»¶", len(files))
            
            if files:
                latest_file = max(files, key=os.path.getctime)
                latest_time = datetime.fromtimestamp(
                    os.path.getctime(latest_file)
                ).strftime("%H:%M:%S")
                st.metric("æœ€æ–°ç”Ÿæˆ", latest_time)
        else:
            st.metric("å·²ç”Ÿæˆæ–‡ä»¶", "0")
    
    # å†å²è®°å½•å’Œæ—¥å¿—
    st.markdown("---")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æ‰§è¡Œå†å²", "ğŸ“‹ ç”Ÿæˆæ–‡ä»¶", "ğŸ” é”™è¯¯æ—¥å¿—"])
    
    with tab1:
        show_execution_history()
    
    with tab2:
        show_generated_files()
    
    with tab3:
        show_error_logs()

def run_workflows(count: int, show_logs: bool = True, show_realtime: bool = True):
    """æ‰§è¡Œå·¥ä½œæµçš„ä¸»å‡½æ•°"""
    runner = WorkflowRunner()
    
    # åˆ›å»ºçŠ¶æ€å®¹å™¨
    status_container = st.container()
    progress_container = st.container()
    
    # å®æ—¶è¾“å‡ºå®¹å™¨
    if show_realtime:
        realtime_container = st.container()
        with realtime_container:
            st.subheader("ğŸ“º å®æ—¶è¾“å‡º")
            log_placeholder = st.empty()
            log_content = []
    
    results_container = st.container()
    
    with status_container:
        st.info(f"ğŸ”„ å‡†å¤‡æ‰§è¡Œ {count} æ¬¡å·¥ä½œæµ...")
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
    
    # æ‰§è¡Œç»Ÿè®¡
    start_time = time.time()
    success_count = 0
    error_count = 0
    
    def update_progress(current: int, total: int):
        progress = current / total
        progress_bar.progress(progress)
        status_text.text(f"æ‰§è¡Œè¿›åº¦: {current}/{total} ({progress:.1%})")
    
    def update_logs(new_logs):
        """æ›´æ–°å®æ—¶æ—¥å¿—æ˜¾ç¤º"""
        if show_realtime:
            log_content.extend(new_logs)
            # åªä¿ç•™æœ€è¿‘çš„50æ¡æ—¥å¿—
            if len(log_content) > 50:
                log_content[:] = log_content[-50:]
            
            # æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºæ—¥å¿—
            formatted_logs = []
            for log in log_content[-20:]:  # åªæ˜¾ç¤ºæœ€è¿‘20æ¡
                if log.strip():
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    formatted_logs.append(f"[{timestamp}] {log.strip()}")
            
            if formatted_logs:
                log_text = "\n".join(formatted_logs)
                # ä½¿ç”¨å”¯ä¸€çš„keyç”Ÿæˆç­–ç•¥
                runner.log_counter += 1
                unique_key = f"log_{int(time.time())}_{runner.log_counter}_{uuid.uuid4().hex[:8]}"
                log_placeholder.text_area(
                    "å®æ—¶æ—¥å¿—",
                    value=log_text,
                    height=300,
                    key=unique_key
                )
    
    # å¼‚æ­¥æ‰§è¡Œ
    async def run_async():
        nonlocal success_count, error_count
        await runner.run_batch_workflows(count, update_progress, update_logs)
        success_count = len(runner.results)
        error_count = len(runner.errors)
    
    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    try:
        asyncio.run(run_async())
    except Exception as e:
        st.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return
    
    # è®¡ç®—æ‰§è¡Œæ—¶é—´
    execution_time = time.time() - start_time
    
    # æ˜¾ç¤ºç»“æœ
    with results_container:
        st.success("âœ… æ‰§è¡Œå®Œæˆï¼")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»æ‰§è¡Œæ¬¡æ•°", count)
        with col2:
            st.metric("æˆåŠŸæ¬¡æ•°", success_count)
        with col3:
            st.metric("å¤±è´¥æ¬¡æ•°", error_count)
        with col4:
            success_rate = (success_count / count) * 100 if count > 0 else 0
            st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
        
        st.text(f"â±ï¸ æ€»è€—æ—¶: {execution_time:.2f} ç§’")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        if show_logs and runner.results:
            with st.expander("ğŸ“‹ æˆåŠŸæ‰§è¡Œè¯¦æƒ…", expanded=False):
                for i, result in enumerate(runner.results[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    content = result['result'].generated_content
                    st.write(f"**ç¬¬ {i+1} æ¬¡æ‰§è¡Œ**")
                    st.write(f"- æ ‡é¢˜: {content.title}")
                    st.write(f"- ä¿å­˜æ–‡ä»¶: {result['saved_file']}")
                    st.write("---")
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if runner.errors:
            with st.expander("âŒ æ‰§è¡Œé”™è¯¯è¯¦æƒ…", expanded=True):
                for error in runner.errors:
                    st.error(f"ç¬¬ {error['index']} æ¬¡æ‰§è¡Œå¤±è´¥: {error['error']}")
        
        # ä¿å­˜æ‰§è¡Œå†å²åˆ°session state
        if 'execution_history' not in st.session_state:
            st.session_state.execution_history = []
        
        st.session_state.execution_history.append({
            'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'count': count,
            'success': success_count,
            'error': error_count,
            'success_rate': f"{success_rate:.1f}%",
            'duration': f"{execution_time:.2f}s"
        })

def show_execution_history():
    """æ˜¾ç¤ºæ‰§è¡Œå†å²"""
    st.subheader("ğŸ“ˆ æ‰§è¡Œå†å²è®°å½•")
    
    if st.session_state.get('execution_history'):
        history = st.session_state.execution_history[-10:]  # æ˜¾ç¤ºæœ€è¿‘10æ¡
        
        for i, record in enumerate(reversed(history)):
            with st.container():
                col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 1])
                with col1:
                    st.text(f"â° {record['time']}")
                with col2:
                    st.text(f"ğŸ“Š {record['count']} æ¬¡")
                with col3:
                    st.text(f"âœ… {record['success']}")
                with col4:
                    st.text(f"âŒ {record['error']}")
                with col5:
                    st.text(f"ğŸ“ˆ {record['success_rate']}")
                
                if i < len(history) - 1:
                    st.divider()
        
        # æ¸…ç©ºå†å²æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰§è¡Œå†å²"):
            st.session_state.execution_history = []
            st.success("æ‰§è¡Œå†å²å·²æ¸…ç©º")
            st.rerun()
    else:
        st.info("æš‚æ— æ‰§è¡Œå†å²è®°å½•")

def show_generated_files():
    """æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶"""
    col_title, col_refresh = st.columns([3, 1])
    
    with col_title:
        st.subheader("ğŸ“‹ ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨")
    
    with col_refresh:
        if st.button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨", help="é‡æ–°åŠ è½½æ–‡ä»¶åˆ—è¡¨"):
            st.rerun()
    
    data_dir = Path("data")
    if not data_dir.exists():
        st.info("data ç›®å½•ä¸å­˜åœ¨ï¼Œæš‚æ— ç”Ÿæˆæ–‡ä»¶")
        return
    
    files = sorted(data_dir.glob("result_*.txt"), key=os.path.getctime, reverse=True)
    
    if not files:
        st.info("æš‚æ— ç”Ÿæˆæ–‡ä»¶")
        return
    
    # æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    total_files = len(files)
    total_size_bytes = sum(f.stat().st_size for f in files)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ–‡ä»¶æ€»æ•°", total_files)
    with col2:
        st.metric("æ€»å¤§å°", f"{total_size_bytes / 1024:.1f} KB")
    with col3:
        if files:
            latest_file = max(files, key=os.path.getctime)
            latest_time = datetime.fromtimestamp(os.path.getctime(latest_file))
            st.metric("æœ€æ–°æ–‡ä»¶", latest_time.strftime("%H:%M:%S"))
    
    st.markdown("---")
    
    # æ–‡ä»¶åˆ—è¡¨
    for file in files[:20]:  # æ˜¾ç¤ºæœ€è¿‘20ä¸ªæ–‡ä»¶
        file_time = datetime.fromtimestamp(os.path.getctime(file))
        file_size = os.path.getsize(file)
        
        with st.container():
            col1, col2, col3, col4, col5 = st.columns([2.5, 1.5, 1, 0.8, 0.8])
            with col1:
                st.text(f"ğŸ“„ {file.name}")
            with col2:
                st.text(f"â° {file_time.strftime('%m-%d %H:%M:%S')}")
            with col3:
                st.text(f"ğŸ“ {file_size} B")
            with col4:
                if st.button("ğŸ‘ï¸", key=f"preview_{file.name}", help="é¢„è§ˆæ–‡ä»¶"):
                    try:
                        with open(file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ", content, height=200, key=f"content_{file.name}")
                    except Exception as e:
                        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            with col5:
                # åˆ é™¤å•ä¸ªæ–‡ä»¶æŒ‰é’®
                if st.button("ğŸ—‘ï¸", key=f"delete_{file.name}", help="åˆ é™¤æ­¤æ–‡ä»¶"):
                    try:
                        file.unlink()
                        st.success(f"âœ… å·²åˆ é™¤ {file.name}")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")

def show_error_logs():
    """æ˜¾ç¤ºé”™è¯¯æ—¥å¿—"""
    st.subheader("ğŸ” é”™è¯¯æ—¥å¿—")
    
    error_log_file = "workflow_errors.log"
    if not os.path.exists(error_log_file):
        st.info("æš‚æ— é”™è¯¯æ—¥å¿—")
        return
    
    try:
        with open(error_log_file, 'r', encoding='utf-8') as f:
            error_content = f.read()
        
        if error_content.strip():
            st.text_area("é”™è¯¯æ—¥å¿—å†…å®¹", error_content, height=300)
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºé”™è¯¯æ—¥å¿—"):
                    with open(error_log_file, 'w') as f:
                        f.write("")
                    st.success("é”™è¯¯æ—¥å¿—å·²æ¸…ç©º")
                    st.rerun()
            
            with col2:
                # ä¸‹è½½é”™è¯¯æ—¥å¿—
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½é”™è¯¯æ—¥å¿—",
                    data=error_content,
                    file_name=f"error_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )
        else:
            st.info("é”™è¯¯æ—¥å¿—ä¸ºç©º")
    
    except Exception as e:
        st.error(f"è¯»å–é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
